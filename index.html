<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lei Sun (Â≠ôÁ£ä)</title>
  
  <meta name="author" content="Lei Sun">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Lei Sun (Â≠ôÁ£ä)</name>
              </p>
              <p> I am a doctoral student at Zhejiang University under the supervision of Prof. <a href="wangkaiwei.org">Kaiwei Wang </a>. 
                I am also a visiting doctoral student at <a href="https://vision.ee.ethz.ch/">Computer Vision Lab</a>, 
                ETH Zurich under the supervision of Prof. <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a>. 
                Before that, I received my bachelor's degree from Beijing Institute of Technology.
              </p>
              <p>
                I am looking for post-doc positions or job opportunities related to event camera, low-level image process, and environment perception algorithms.
              </p>
              <p style="text-align:center">
                <a href="mailto:leo_sun@zju.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/sunlei_cv_23July.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=VLFyM50AAAAJ&hl">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/lei-sun-ab6533246/">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/ahupujr/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/SunLei.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/SunLei.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, image processing and event cameras. First-author papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr> 
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
          <!-- papers -->
          <tr bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/Evdeblur_before.png" alt="evdeblur" width="160" height="160">
          </td>
          <td width="75%" valign="middle">
            <!-- <td style="padding:20px;width:75%;vertical-align:middle"> -->
              <a href="https://ahupujr.github.io/EFNet/">
                <papertitle>Event-Based Fusion for Motion Deblurring with Cross-modal Attention</papertitle>
              </a>
              <br>
              <strong>Lei Sun</strong>,
              <a href="https://people.ee.ethz.ch/~csakarid">Christos Sakaridis</a>, 
							<a href="https://jingyunliang.github.io">Jingyun Liang</a>, 
              <a>Qi Jiang</a>,
              <a href="https://yangkailun.com">Kailun Yang</a>,
              <a>Peng Sun</a>,
              <br>
              <a>Yaozu Ye</a>,
              <a href="https://wangkaiwei.org">Kaiwei Wang</a>,
              <a href="https://scholar.google.com/citations?user=TwMib_QAAAAJ&hl">Luc Van Gool</a>

              <br>
              <em>ECCV</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation, rate:2.7%)</strong></font>
              <br>
              <a href="https://ahupujr.github.io/EFNet/">project page</a>
              /
              <a href="https://github.com/AHupuJR/EFNet">codes</a>
              /
              <a href="https://arxiv.org/abs/2112.00167">arXiv</a>
              <p></p>
              <p>
                We present a novel event-based deblurring method that improves the previous state-of-the-art by 2.47 dB.
              </p>
            <!-- </td> -->
            </td>
          </tr>


      <!-- papers -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/PALrestore.jpg" alt="PALrestore" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <!-- <a href="xx"> -->
            <papertitle>Compact and lightweight panoramic annular lens for computer vision tasks</papertitle>
          <!-- </a> -->
          <br>
          Shaohua Gao, <strong>Lei Sun</strong>, Qi Jiang, Hao Shi, Jia Wang, <a href="https://wangkaiwei.org">Kaiwei Wang</a>, Jian Bai
          <br>
          <em>Optical Express</em>, 2022
          <p>Designing a lightweight panoramic annular lens with physical-based image enhancement model.</p>
        </td>
      </tr>
      <!-- papers -->

      <!-- papers -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/Wangjia_seg.png" alt="Wangjia_seg" width="160" height="120">
        </td>
        <td width="75%" valign="middle">
          <a href="https://yangkailun.com/publications/oe2022_jia.pdf">
            <papertitle>High-performance panoramic annular lens design for real-time semantic segmentation on aerial imagery</papertitle>
          </a>
          <br>
          Jia Wang, <a href="https://yangkailun.com">Kailun Yang</a>, Shaohua Gao, <strong>Lei Sun</strong>, Chenxi Zhu, <a href="https://wangkaiwei.org">Kaiwei Wang</a>, Jian Bai
          <br>
          <em>Optical Engineering</em> 61 (3), 035101, 2022
          <p>Designing a panoramic annular lens (PAL) system with 4K high resolution for aerial image segmentation.</p>
        </td>
      </tr>
      <!-- papers -->

      <!-- papers -->
      <tr bgcolor="#ffffd0"> 
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/Aerial_pass.png" alt="Aerial_pass" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <a href="https://arxiv.org/pdf/2105.07209.pdf">
            <papertitle>Aerial-PASS: panoramic annular scene segmentation in drone videos</papertitle>
          </a>
          <br>
          <strong>Lei Sun</strong>, Jia Wang, <a href="https://yangkailun.com">Kailun Yang</a>, Kaikai Wu, Xiangdong Zhou, <a href="https://wangkaiwei.org">Kaiwei Wang</a>, Jian Bai
          <br>
          <em>European Conference on Mobile Robots (ECMR)</em> 2021
          <p>Designing a specific semantic segmentation for aerial panoramic images.</p>
        </td>
      </tr>
      <!-- papers -->


      <!-- papers -->
      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/RFNet.png" alt="RFNet" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <a href="https://arxiv.org/pdf/2002.10570.pdf">
            <papertitle>Real-time fusion network for RGB-D semantic segmentation incorporating unexpected obstacle detection for road-driving images</papertitle>
          </a>
          <br>
          <strong>Lei Sun</strong>, <a href="https://yangkailun.com">Kailun Yang</a>, Xinxin Hu, Weijian Hu, <a href="https://wangkaiwei.org">Kaiwei Wang</a>
          <br>
          <em>IEEE Robotics and Automation Letters and IROS</em>, 2020
          <br>
          <a href="https://github.com/AHupuJR/EFNet">codes</a>
          <br>
          <p>A real-time RGB-D fusion semantic segmentation framework with small obstacle detection.</p>
        </td>
      </tr>
      <!-- papers -->

      <!-- papers -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/weijian_vip.png" alt="weijian_vip" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=VLFyM50AAAAJ&citation_for_view=VLFyM50AAAAJ:W7OEmFMy1HYC">
            <papertitle>A comparative study in real-time scene sonification for visually impaired people</papertitle>
          </a>
          <br>
          Weijian Hu, <a href="https://wangkaiwei.org">Kaiwei Wang</a>, <a href="https://yangkailun.com">Kailun Yang</a>, Ruiqi Cheng, Yaozu Ye, <strong>Lei Sun</strong>, Zhijie Xu
          <br>
          <em>Sensors</em> 20 (11), 3222, 2020
          <p>Propose three different auditory-based interaction methods which convey raw depth images,
            obstacle information and path information respectively to visually impaired people.</p>
        </td>
      </tr>
      <!-- papers -->


      <!-- papers -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/Yichen_localization.png" alt="yichen_loal" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=VLFyM50AAAAJ&citation_for_view=VLFyM50AAAAJ:WF5omc3nYNoC">
            <papertitle>A panoramic localizer based on coarse-to-fine descriptors for navigation assistance</papertitle>
          </a>
          <br>
          Yicheng Fang,  <a href="https://yangkailun.com">Kailun Yang</a>, Ruiqi Cheng, <strong>Lei Sun</strong>, <a href="https://wangkaiwei.org">Kaiwei Wang</a>
          <br>
          <em>Sensors</em> 20 (15), 4177, 2020
          <p>Propose a panoramic
            localizer, which is based on coarse-to-fine descriptors, leveraging panoramas for omnidirectional
            perception and sufficient FoV up to 360‚ó¶.</p>
        </td>
      </tr>
      <!-- papers -->


      <!-- papers -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/yyz_journal.png" alt="yyz_journal" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <a href="https://iopscience.iop.org/article/10.1088/1742-6596/1229/1/012026/pdf">
            <papertitle>A wearable vision-to-audio sensory substitution device for blind assistance and the correlated neural substrates</papertitle>
          </a>
          <br>
          Yaozu Ye, <a href="https://wangkaiwei.org">Kaiwei Wang</a>, Weijian Hu, Huabing Li, <a href="https://yangkailun.com">Kailun Yang</a>, <strong>Lei Sun</strong>, Zuobing Chen
          <br>
          <em>Journal of Physics: Conference Series</em> 1229 (1), 012026, 2019
          <p>Develop a wearable system to transform the
            spatial information captured by camera into a voice description and fed it back to blind users.
          </p>
        </td>
      </tr>
      <!-- papers -->

      <!-- papers -->
      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/day2night.png" alt="day2night" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <a href="https://arxiv.org/pdf/1908.05868.pdf">
            <papertitle>See Clearer at Night: Towards Robust Nighttime Semantic Segmentation through Day-Night Image Conversion</papertitle>
          </a>
          <br>
          <strong>Lei Sun</strong>, <a href="https://yangkailun.com">Kailun Yang</a>, <a href="https://wangkaiwei.org">Kaiwei Wang</a>, Kaite Xiang
          <br>
          <em>Artificial Intelligence and Machine Learning in Defense Applications, SPIE</em> 1229 (1), 012026, 2019
          <p>Propose a
            framework to alleviate the accuracy decline when semantic segmentation is taken to adverse conditions by using
            Generative Adversarial Networks (GANs).
          </p>
        </td>
      </tr>
      <!-- papers -->



        </tbody></table>




        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr> -->
					

          <!-- <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr> -->
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website template from <a href="https://jonbarron.info">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
